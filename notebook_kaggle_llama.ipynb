{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Domain Adaptation using QLoRA\n\nThis notebook demonstrates how to:\n1. Extract text from a technical PDF\n2. Prepare training data for causal language modelling (CLM)\n3. Fine-tune a language (llama 3.2 3b) base model using QLoRA\n4. Apply the QLoRA and the learned weights to the instruct model\n5. Answer some test questions","metadata":{}},{"cell_type":"code","source":"# Clone the git repo to access the utilities\n!git clone https://github.com/arminwitte/mistral-peft mistralpeft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:08:08.503100Z","iopub.execute_input":"2025-02-23T21:08:08.503339Z","iopub.status.idle":"2025-02-23T21:08:08.637667Z","shell.execute_reply.started":"2025-02-23T21:08:08.503318Z","shell.execute_reply":"2025-02-23T21:08:08.636462Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'mistralpeft' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Make sure to be on the repo directory and pull\nimport os\nif not os.getcwd() == \"/kaggle/working/mistralpeft\":\n    os.chdir(\"/kaggle/working/mistralpeft\")\n!pwd\n!git fetch --all\n!git reset --hard origin/main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:08:12.211600Z","iopub.execute_input":"2025-02-23T21:08:12.211887Z","iopub.status.idle":"2025-02-23T21:08:41.014712Z","shell.execute_reply.started":"2025-02-23T21:08:12.211863Z","shell.execute_reply":"2025-02-23T21:08:41.013833Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"/kaggle/working/mistralpeft\nFetching origin\nremote: Enumerating objects: 17, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Total 17 (delta 7), reused 7 (delta 7), pack-reused 10 (from 1)\u001b[K\nUnpacking objects: 100% (17/17), 341.66 MiB | 13.71 MiB/s, done.\nFrom https://github.com/arminwitte/mistral-peft\n   88d57ca..3fddfb9  main       -> origin/main\nUpdating files: 100% (37/37), done.\nHEAD is now at 3fddfb9 update r=16\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Install the required packages from pypi\n!pip install -r requirements.txt --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:33:56.524072Z","iopub.execute_input":"2025-02-23T21:33:56.524501Z","iopub.status.idle":"2025-02-23T21:34:03.794516Z","shell.execute_reply.started":"2025-02-23T21:33:56.524469Z","shell.execute_reply":"2025-02-23T21:34:03.793536Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load packages\nfrom transformers import Trainer, TrainingArguments, AutoTokenizer, pipeline\nfrom pathlib import Path\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftConfig, PeftModel\nfrom datasets import Dataset\n\nfrom mistralpeft.utils import TextExtractor, CLMPreprocessor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:47:15.322275Z","iopub.execute_input":"2025-02-23T21:47:15.322650Z","iopub.status.idle":"2025-02-23T21:47:38.444372Z","shell.execute_reply.started":"2025-02-23T21:47:15.322622Z","shell.execute_reply":"2025-02-23T21:47:38.443701Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Login to HuggingFace using Kaggle's secrets to be able to download models\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"huggingface\")\nlogin(secret_value_0) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:47:50.607459Z","iopub.execute_input":"2025-02-23T21:47:50.608102Z","iopub.status.idle":"2025-02-23T21:47:51.002301Z","shell.execute_reply.started":"2025-02-23T21:47:50.608068Z","shell.execute_reply":"2025-02-23T21:47:51.001559Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 1. Extract Sentences from PDF\nSeveral PDFs from my former research group at university (Thermo-Fluiddynamics Group, Prof. Polifke) are chosen to form the corpus","metadata":{}},{"cell_type":"code","source":"# TextExtractor is a simple ETL class to acquire a text corpus\npdf_files = [\n    \"Dissertation.pdf\",\n]\n    \npdf_urls = [\n    \"https://mediatum.ub.tum.de/doc/1360567/1360567.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1601190/1601190.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1597610/1597610.pdf\"\n    \"https://mediatum.ub.tum.de/doc/1584750/1584750.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1484812/1484812.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1335646/1335646.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1326486/1326486.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1306410/1306410.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1444929/1444929.pdf\",\n]\n\ndata_path = Path(\"data/processed_documents.json\")\nif not data_path.is_file():\n    with TextExtractor(\"data/processed_documents.json\") as extractor:\n        # Process local files\n        extractor.process_documents(pdf_files)\n            \n        # Process URLs\n        extractor.process_documents(pdf_urls, url_list=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:47:57.935510Z","iopub.execute_input":"2025-02-23T21:47:57.935810Z","iopub.status.idle":"2025-02-23T21:47:57.940399Z","shell.execute_reply.started":"2025-02-23T21:47:57.935787Z","shell.execute_reply":"2025-02-23T21:47:57.939401Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 2. Prepare MCLM Training Data","metadata":{}},{"cell_type":"code","source":"# Specify the model and load the tokenizer\n# Llama 3.2 3B with approx. 3 billion parameters\nmodel_name = \"meta-llama/Llama-3.2-3B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:48:02.505195Z","iopub.execute_input":"2025-02-23T21:48:02.505538Z","iopub.status.idle":"2025-02-23T21:48:04.332111Z","shell.execute_reply.started":"2025-02-23T21:48:02.505486Z","shell.execute_reply":"2025-02-23T21:48:04.331451Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed79481a531649b0a24977e6ba61bdaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b32505c971fb423b8ba45563af0ed81f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a50f052edb5f41aa9440d0a74d5ba991"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Preprocess the corpus for Causal Language Modeling (CLM)\njson_file_paths = [\"data/processed_documents.json\"]\npreprocessor = CLMPreprocessor(json_file_paths, tokenizer)\ndataset = preprocessor.preprocess()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:48:14.139095Z","iopub.execute_input":"2025-02-23T21:48:14.139438Z","iopub.status.idle":"2025-02-23T21:48:17.799851Z","shell.execute_reply.started":"2025-02-23T21:48:14.139410Z","shell.execute_reply":"2025-02-23T21:48:17.799172Z"}},"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (152682 > 131072). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Split into training and test set\ntrain_test_set = dataset.train_test_split(test_size=0.1)\nprint(f\"Created {len(train_test_set['train'])} training examples and {len(train_test_set['test'])} test examples\")\n\n# Preview a training example\nexample = train_test_set[\"train\"][0]\nprint(\"\\nExample input:\")\nprint(preprocessor.tokenizer.decode(example['input_ids'][:256]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:48:39.875519Z","iopub.execute_input":"2025-02-23T21:48:39.875860Z","iopub.status.idle":"2025-02-23T21:48:39.906673Z","shell.execute_reply.started":"2025-02-23T21:48:39.875834Z","shell.execute_reply":"2025-02-23T21:48:39.905992Z"}},"outputs":[{"name":"stdout","text":"Created 232 training examples and 26 test examples\n\nExample input:\n2. ISSN 00457825. doi: 10.01016/0045-7825(82)90071-8. T. J. Hughes, L. P. Franca, and G. M. Hulbert. “A new ﬁnite element formulation for com- putational ﬂuid dynamics: VIII. The Galerkin/least-squares method for advective-diffusive equations”. Computer Methods in Applied Mechanics and Engineering, 73(2):173–189, May 1989. ISSN 00457825. doi: 10.01016/0045-7825(89)90111-4. T. Hofmeister, T. Hummel, B. Schuermans, and T. Sattelmayer. “Quantiﬁcation of Energy Transformation Processes Between Acoustic and Hydrodynamic Modes in Non-Compact Thermoacoustic Systems via a Helmholtz-Hodge Decomposition Approach”. In Volume 4 A: Combustion, Fuels, and Emissions, page V 04 AT 04 A 013, Phoenix, Arizona, USA, June 2019. American Society of Mechanical Engineers. ISBN 978-0-7918-586\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 3. Load and Prepare Model","metadata":{}},{"cell_type":"code","source":"# Load the base model\n# Q4_K_M quantization of the base model is achieved through BitsAndBytes. It requires CUDA!\nquantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,  # Use load_in_4bit=True for 4-bit quantization\n        bnb_4bit_quant_type=\"nf4\", # use normalized float 4\n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_use_double_quant=False, # do not quantize scaling factors for Q4_K_M\n    )\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    quantization_config=quantization_config,\n    )\nif base_model.config.pad_token_id is None:\n    base_model.config.pad_token_id = base_model.config.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:48:50.611646Z","iopub.execute_input":"2025-02-23T21:48:50.611944Z","iopub.status.idle":"2025-02-23T21:51:32.658528Z","shell.execute_reply.started":"2025-02-23T21:48:50.611920Z","shell.execute_reply":"2025-02-23T21:51:32.657648Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b1210f61fa4498b84342678bccd3c6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3290e43ccdb4a0ea1c5718d89868d44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a05e2f7be3b04b1cbb0a6c3c17a62a80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8353f2485f8a4bd5bf3fbdc06841d8ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e4b3bd7f63c408881220d2e056e36f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfe5998b5232466fb43e9140fdc17f04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c07fd72890e4e5394d0b69ead49df36"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Configure the (Q)LoRA adaptor to use a rank of r=4\nmodel = prepare_model_for_kbit_training(base_model)\nconfig = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\npeft_model = get_peft_model(model, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T07:47:31.007834Z","iopub.execute_input":"2025-02-23T07:47:31.008051Z","iopub.status.idle":"2025-02-23T07:47:31.544063Z","shell.execute_reply.started":"2025-02-23T07:47:31.008033Z","shell.execute_reply":"2025-02-23T07:47:31.543361Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## 4. Train the Model\n\nThe LoRA adapter has about 6M parameters to train (compared to 3B parameters of the full LLM)","metadata":{}},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=10,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=3, # Creates a virtual batch size of 3\n    learning_rate=3e-4,\n    fp16=True, # numerical precision of adapter is float16\n    logging_steps=1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    optim=\"paged_adamw_8bit\", # Memory efficient optimizer\n    log_level=\"info\",\n    report_to=\"none\",\n)\n\n# Initialize trainer\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=train_test_set['train'],\n    eval_dataset=train_test_set['test']\n)\n\n# Start training\ntrainer.train(resume_from_checkpoint=False)#\"results/checkpoint-231\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T07:47:31.544877Z","iopub.execute_input":"2025-02-23T07:47:31.545115Z","execution_failed":"2025-02-23T07:51:15.945Z"}},"outputs":[{"name":"stderr","text":"Using auto half precision backend\n***** Running training *****\n  Num examples = 232\n  Num Epochs = 10\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 3\n  Gradient Accumulation steps = 3\n  Total optimization steps = 770\n  Number of trainable parameters = 24,313,856\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5' max='770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  5/770 02:41 < 11:25:34, 0.02 it/s, Epoch 0.05/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Save the LoRA adapter weights:\nlora_save_path = \"lora_weights\" \npeft_model.save_pretrained(lora_save_path)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-23T07:51:15.947Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Apply the learned weights to the instruct model","metadata":{}},{"cell_type":"code","source":"# Load the instruct model\nquantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,  # Use load_in_4bit=True for 4-bit quantization\n        bnb_4bit_quant_type=\"nf4\", # use normalized float 4\n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_use_double_quant=False, # do not quantize scaling factors\n    )\nmodel_name = \"meta-llama/Llama-3.2-3B-Instruct\"\ninstruct_tokenizer = AutoTokenizer.from_pretrained(model_name)\ninstruct_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    # quantization_config=quantization_config,\n)\nif instruct_tokenizer.pad_token_id is None:\n    instruct_tokenizer.pad_token_id = instruct_tokenizer.eos_token_id\nif instruct_model.config.pad_token_id is None:\n    instruct_model.config.pad_token_id = instruct_model.config.eos_token_id\n\n# Load the LoRA configuration and weights\n# lora_weights_path = \"lora_weights\"\nlora_weights_path = \"results/checkpoint-231\"\n# peft_config = PeftConfig.from_pretrained(lora_weights_path)\n\n# Apply LoRA adapter to the instruct model\nlora_instruct_model = PeftModel.from_pretrained(instruct_model, lora_weights_path)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T22:02:54.025021Z","iopub.execute_input":"2025-02-23T22:02:54.025378Z","iopub.status.idle":"2025-02-23T22:03:02.705093Z","shell.execute_reply.started":"2025-02-23T22:02:54.025349Z","shell.execute_reply":"2025-02-23T22:03:02.704153Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e2700684864865862fc31704e27fce"}},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## 6. Test the Model","metadata":{}},{"cell_type":"code","source":"def test_qanda(model, tokenizer):\n    # Example queries\n    queries = [\n        \"Explain the CFD/SI method.\",\n        \"What is a Rijke tube?\",\n        \"How is a finite impulse response computed?\",\n        \"When analyzing heat transfer using system identification, what key criteria were used to validate the identified models, and what minimum performance threshold was considered acceptable?\",\n        \"For a heated cylinder in pulsating cross-flow at Reynolds numbers between 0.4-40, what explains the appearance of amplitude peaks in the frequency response at Strouhal numbers between 0-1, and how does this behavior change with Reynolds number?\",\n    ]\n\n    # Create pipeline for inference\n    pipe = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n    )\n    \n    # Generate responses\n    for query in queries:\n        messages = [{\"role\": \"user\", \"content\": query}]\n        prompt = tokenizer.apply_chat_template(\n            messages, tokenize=False, add_generation_prompt=True\n        )\n\n        outputs = pipe(prompt, max_new_tokens=120, do_sample=True)\n        \n        print(f\"\\nQuery: {query}\")\n        print(f\"\\nResponse: {outputs[0]['generated_text']}\")\n        print(\"-\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T22:03:13.982342Z","iopub.execute_input":"2025-02-23T22:03:13.982665Z","iopub.status.idle":"2025-02-23T22:03:13.987777Z","shell.execute_reply.started":"2025-02-23T22:03:13.982641Z","shell.execute_reply":"2025-02-23T22:03:13.987014Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def test_qanda2(model, tokenizer):# Example queries\n    queries = [\n        \"Explain the CFD/SI method.\",\n        \"What is a Rijke tube?\",\n        \"How is a finite impulse response computed?\",\n        \"When analyzing heat transfer using system identification, what key criteria were used to validate the identified models, and what minimum performance threshold was considered acceptable?\",\n        \"For a heated cylinder in pulsating cross-flow at Reynolds numbers between 0.4-40, what explains the appearance of amplitude peaks in the frequency response at Strouhal numbers between 0-1, and how does this behavior change with Reynolds number?\",\n    ]\n    \n    # Generate responses\n    for query in queries:\n        messages = [{\"role\": \"user\", \"content\": query}]\n    \n        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            \n        inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n        \n        outputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n        \n        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        print(f\"\\nQuery: {query}\")\n        print(f\"\\nResponse: {text.split('assistant')[1]}\")\n        print(\"-\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T21:55:21.799620Z","iopub.execute_input":"2025-02-23T21:55:21.799955Z","iopub.status.idle":"2025-02-23T21:55:21.805380Z","shell.execute_reply.started":"2025-02-23T21:55:21.799924Z","shell.execute_reply":"2025-02-23T21:55:21.804540Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### 6.1 Answers to the test questions by the instruct model w/o LoRA","metadata":{}},{"cell_type":"code","source":"test_qanda(instruct_model, instruct_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T22:03:19.362683Z","iopub.execute_input":"2025-02-23T22:03:19.362965Z","iopub.status.idle":"2025-02-23T22:03:50.371786Z","shell.execute_reply.started":"2025-02-23T22:03:19.362944Z","shell.execute_reply":"2025-02-23T22:03:50.371002Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"\nQuery: Explain the CFD/SI method.\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nExplain the CFD/SI method.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nCF/S ( Finite Element/ Finite) is a numerical technique used to solve partial differential equations (DE) in fields such as fluid, heat, and mass transfer. is a method for solving partial differential equations using finite elements and finite difference. It is widely used in fields such as engineering, physics, and.\n--------------------------------------------------------------------------------\n\nQuery: What is a Rijke tube?\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat is a Rijke tube?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nA Rijke tube is a device used in physics to generate aacoustic or sound amplification. It is typically a tube with two ends open, and a narrow neck connecting the ends. The tube is filled with a gas, usually air or helium, and a piston is inserted at one end. When the piston is pushed and pulled, it creates a wave in the gas, which then resonates in the tube.\n\nThe R tube is often used in various applications such as in ultrasonic devices, instruments, and devices for generating sound waves in fields like medicine, materials science, and industry.\n--------------------------------------------------------------------------------\n\nQuery: How is a finite impulse response computed?\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nHow is a finite impulse response computed?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nA finite impulse response (IR) is a mathematical that describes the output of a system when it is excited by a impulse, i.e when input is zero but output is not. It is computed by taking the convolution of input signal with inverse impulse.\n--------------------------------------------------------------------------------\n\nQuery: When analyzing heat transfer using system identification, what key criteria were used to validate the identified models, and what minimum performance threshold was considered acceptable?\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhen analyzing heat transfer using system identification, what key criteria were used to validate the identified models, and what minimum performance threshold was considered acceptable?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nWhen analyzing heat transfer using system identification, several criteria are used to validate the identified models. The criteria and performance thresholds may vary depending on the specific application, complexity of system, and requirements. Here are some common criteria and thresholds:\n\n1. Root Mean Square (MS) Error: The MS error is a measure of difference between predicted and actual values. a acceptable threshold is typically set around %  %  %  % % % %  % % % % %  % % % %  %  %\n--------------------------------------------------------------------------------\n\nQuery: For a heated cylinder in pulsating cross-flow at Reynolds numbers between 0.4-40, what explains the appearance of amplitude peaks in the frequency response at Strouhal numbers between 0-1, and how does this behavior change with Reynolds number?\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nFor a heated cylinder in pulsating cross-flow at Reynolds numbers between 0.4-40, what explains the appearance of amplitude peaks in the frequency response at Strouhal numbers between 0-1, and how does this behavior change with Reynolds number?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nThe behavior you're describing is related to the dynamics of pulsating flow in a cylinder., in flow with cylinder. The Strhal number (,) is a dimensionless that relates the frequency of oscillations the flow and the flow number the flow. The flow number is defined as number flow =  u2τ, where u the flow velocity the flow andτ the time the. The number the flow is the ratio the inert to viscous times the flow the, and is defined as number = uτ. the number flow the is a of the flow the. the flow is the of\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"test_qanda2(instruct_model, instruct_tokenizer)","metadata":{"trusted":true},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nQuery: Explain the CFD/SI method.\n\nResponse: \n\nCF/S ( C/S stands forcompress and) is a numerical method used solvecompress fluid flow problems In, it combines compress flow simulations theacics,acics and dynamics. is based on Nav-Stu s equations the, is the, and, the,. is a of in linear and linear,, of and, the. is a of the, and the,, the, the, the, and the. is a of the, and the, and the, the, and the, the, and. is of the, and the, the, the, and the, the and the, the, the, and the. is a of the, the, the, the and the, the, the and, the\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nQuery: What is a Rijke tube?\n\nResponse: \n\nA Rijke tube is a device used in physics to create a vacuum through a process known as Joule's law of, the of expansion of gases. It was invented by Dutch physicist D. Rijke in 1850. The tube consists of a metal tube with a end, one end closed and other end open. The tube is heated from one end, the heated end is then rotated at a speed so the heated air inside the is forced to expand. The expansion of air creates a pressure difference between ends of tube, creating a pressure gradient. the pressure difference is sufficient create a vacuum the other end the tube\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nQuery: How is a finite impulse response computed?\n\nResponse: \n\nA finite impulse response (IR) is a mathematical that represents the output of a system when a impulse is applied to it. is computed by taking the convolution of input signal with impulse. convolution is defined as:\n\n(x) = () �� � �� �� ������������������������������������������������������������������������������������������������\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-9d648d9f749f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_qanda2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruct_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruct_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-82ec0b91f254>\u001b[0m in \u001b[0;36mtest_qanda2\u001b[0;34m(model, tokenizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2253\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3252\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3254\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    911\u001b[0m                 )\n\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    914\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    641\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mtorch_result_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mactive_adapter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_adapters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":22},{"cell_type":"markdown","source":"### 6.2 Answers to the test questions by the adapted model","metadata":{}},{"cell_type":"code","source":"test_qanda(lora_instruct_model, instruct_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T22:04:47.090047Z","iopub.execute_input":"2025-02-23T22:04:47.090487Z","iopub.status.idle":"2025-02-23T22:05:25.339047Z","shell.execute_reply.started":"2025-02-23T22:04:47.090451Z","shell.execute_reply":"2025-02-23T22:05:25.338297Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nThe model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM'].\n","output_type":"stream"},{"name":"stdout","text":"\nQuery: Explain the CFD/SI method.\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nExplain the CFD/SI method.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nCF/S ( Finite Element/S Method is a numerical technique used solve partial differential equations (DEs) by discretizing domain into smaller, elements. elements are typically rectangular or triangular. is a method used solve partial differential equations (s) by discret the domain into smaller, elements typically rectangular triangular. is a method used solve partial equations by discret the domain smaller, elements typically rectangular triangular. is numerical technique solve partial equations discret domain smaller elements typically rectangular triangular The C/S method a numerical technique solve partial equations discret domain smaller elements typically rectangular triangular\n--------------------------------------------------------------------------------\n\nQuery: What is a Rijke tube?\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat is a Rijke tube?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nA Rijke tube is a device used in physics to generate a vacuum by creating a pressure difference between two volumes. It is named after the Dutch physicist Johannes Rijke, who invented the device in 1876. The device consists of a cylindrical tube with a narrow neck, one end of which is partially closed, while the other end is open. The tube is connected to a pump, which creates a pressure difference between the two volumes.\n\nAs the pump draws air into the tube, it creates a pressure difference between the closed end and the open end. The pressure at the closed end is higher than\n--------------------------------------------------------------------------------\n\nQuery: How is a finite impulse response computed?\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nHow is a finite impulse response computed?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nA finite impulse response (IR) is a fundamental concept in signal processing, and it's used to describe the output of a system when a impulse is applied to it. Here's how it's computed:\n\n**Definition:**\n\nA impulse is a function that is equal to  (1) at time t = 0 and 0 everywhere else. It's often represented as δ(t). The response of a system to an impulse is den by the convolution of impulse with system response function. If system function is f(t) then response is given by convolution f ∗δ\n\n**Math:**\n\n\n--------------------------------------------------------------------------------\n\nQuery: When analyzing heat transfer using system identification, what key criteria were used to validate the identified models, and what minimum performance threshold was considered acceptable?\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhen analyzing heat transfer using system identification, what key criteria were used to validate the identified models, and what minimum performance threshold was considered acceptable?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nwhen analyzing heat transfer using system identification, key criteria used validate identified models typically include:\n\n1. of the model against reference data: models are compared their measured data reference data a range validation metrics such as root mean squared (MS) error mean absolute () errorMAE or root mean squared ()MSSE and coefficient determination determination the of model against data a measure how well model explains underlying dynamics the data\n2 the of model against data a measure how well model captures dynamics data any deviations model from data considered acceptable acceptable minimum threshold the of between model data reference data acceptable threshold a measure the of model\n--------------------------------------------------------------------------------\n\nQuery: For a heated cylinder in pulsating cross-flow at Reynolds numbers between 0.4-40, what explains the appearance of amplitude peaks in the frequency response at Strouhal numbers between 0-1, and how does this behavior change with Reynolds number?\n\nResponse: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 23 Feb 2025\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nFor a heated cylinder in pulsating cross-flow at Reynolds numbers between 0.4-40, what explains the appearance of amplitude peaks in the frequency response at Strouhal numbers between 0-1, and how does this behavior change with Reynolds number?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nThe appearance of amplitude peaks in the frequency response of a heated cylinder in puls cross-flow is due to the interplay between conv heat and flow. the response of a cylinder a a cylinder to puls pertations is by conv heat transfer. heat transfer, in, turn is by conduction and convection The heat transfer is enhanced when flow is puls, as puls pertations conv the boundary layer on cylinder surface This leads to a in flow velocity, which in turn affects heat transfer The frequency of pertations and flow velocity, in, are related by Strhal number Strhal number defined Strhal number a\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}