{
  "best_metric": 3.3748056888580322,
  "best_model_checkpoint": "./results/checkpoint-78",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 78,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01293103448275862,
      "grad_norm": NaN,
      "learning_rate": 0.0003,
      "loss": 35.1608,
      "step": 1
    },
    {
      "epoch": 0.02586206896551724,
      "grad_norm": 9.498631477355957,
      "learning_rate": 0.0002987012987012987,
      "loss": 31.9126,
      "step": 2
    },
    {
      "epoch": 0.03879310344827586,
      "grad_norm": Infinity,
      "learning_rate": 0.0002987012987012987,
      "loss": 30.7244,
      "step": 3
    },
    {
      "epoch": 0.05172413793103448,
      "grad_norm": 10.979710578918457,
      "learning_rate": 0.0002974025974025974,
      "loss": 29.3,
      "step": 4
    },
    {
      "epoch": 0.06465517241379311,
      "grad_norm": 20.201818466186523,
      "learning_rate": 0.0002961038961038961,
      "loss": 25.5387,
      "step": 5
    },
    {
      "epoch": 0.07758620689655173,
      "grad_norm": Infinity,
      "learning_rate": 0.0002961038961038961,
      "loss": 26.5997,
      "step": 6
    },
    {
      "epoch": 0.09051724137931035,
      "grad_norm": Infinity,
      "learning_rate": 0.0002961038961038961,
      "loss": 30.392,
      "step": 7
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 40.31182861328125,
      "learning_rate": 0.0002948051948051948,
      "loss": 27.9939,
      "step": 8
    },
    {
      "epoch": 0.11637931034482758,
      "grad_norm": 26.062610626220703,
      "learning_rate": 0.00029350649350649345,
      "loss": 21.8951,
      "step": 9
    },
    {
      "epoch": 0.12931034482758622,
      "grad_norm": 20.186119079589844,
      "learning_rate": 0.00029220779220779215,
      "loss": 19.3927,
      "step": 10
    },
    {
      "epoch": 0.14224137931034483,
      "grad_norm": 12.654959678649902,
      "learning_rate": 0.0002909090909090909,
      "loss": 17.9054,
      "step": 11
    },
    {
      "epoch": 0.15517241379310345,
      "grad_norm": 24.66238784790039,
      "learning_rate": 0.00028961038961038956,
      "loss": 17.7884,
      "step": 12
    },
    {
      "epoch": 0.16810344827586207,
      "grad_norm": 14.557443618774414,
      "learning_rate": 0.00028831168831168827,
      "loss": 17.2697,
      "step": 13
    },
    {
      "epoch": 0.1810344827586207,
      "grad_norm": 44.95820236206055,
      "learning_rate": 0.000287012987012987,
      "loss": 13.6747,
      "step": 14
    },
    {
      "epoch": 0.1939655172413793,
      "grad_norm": 14.186003684997559,
      "learning_rate": 0.0002857142857142857,
      "loss": 16.066,
      "step": 15
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 8.028042793273926,
      "learning_rate": 0.0002844155844155844,
      "loss": 12.5398,
      "step": 16
    },
    {
      "epoch": 0.21982758620689655,
      "grad_norm": 6.74392032623291,
      "learning_rate": 0.0002831168831168831,
      "loss": 15.262,
      "step": 17
    },
    {
      "epoch": 0.23275862068965517,
      "grad_norm": 6.337515354156494,
      "learning_rate": 0.0002818181818181818,
      "loss": 15.2952,
      "step": 18
    },
    {
      "epoch": 0.24568965517241378,
      "grad_norm": 6.145899295806885,
      "learning_rate": 0.0002805194805194805,
      "loss": 14.9373,
      "step": 19
    },
    {
      "epoch": 0.25862068965517243,
      "grad_norm": 8.621206283569336,
      "learning_rate": 0.0002792207792207792,
      "loss": 14.8593,
      "step": 20
    },
    {
      "epoch": 0.27155172413793105,
      "grad_norm": 5.0739827156066895,
      "learning_rate": 0.0002779220779220779,
      "loss": 14.6853,
      "step": 21
    },
    {
      "epoch": 0.28448275862068967,
      "grad_norm": 3.915724754333496,
      "learning_rate": 0.00027662337662337657,
      "loss": 14.5162,
      "step": 22
    },
    {
      "epoch": 0.2974137931034483,
      "grad_norm": 4.684821605682373,
      "learning_rate": 0.0002753246753246753,
      "loss": 14.7288,
      "step": 23
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 4.584661960601807,
      "learning_rate": 0.00027402597402597403,
      "loss": 13.4752,
      "step": 24
    },
    {
      "epoch": 0.3232758620689655,
      "grad_norm": 4.488706588745117,
      "learning_rate": 0.0002727272727272727,
      "loss": 14.558,
      "step": 25
    },
    {
      "epoch": 0.33620689655172414,
      "grad_norm": 3.4738681316375732,
      "learning_rate": 0.0002714285714285714,
      "loss": 13.0702,
      "step": 26
    },
    {
      "epoch": 0.34913793103448276,
      "grad_norm": 4.489497184753418,
      "learning_rate": 0.0002701298701298701,
      "loss": 13.2133,
      "step": 27
    },
    {
      "epoch": 0.3620689655172414,
      "grad_norm": 3.348630428314209,
      "learning_rate": 0.0002688311688311688,
      "loss": 13.708,
      "step": 28
    },
    {
      "epoch": 0.375,
      "grad_norm": 3.9648547172546387,
      "learning_rate": 0.0002675324675324675,
      "loss": 12.8631,
      "step": 29
    },
    {
      "epoch": 0.3879310344827586,
      "grad_norm": 4.0243120193481445,
      "learning_rate": 0.0002662337662337662,
      "loss": 12.6698,
      "step": 30
    },
    {
      "epoch": 0.40086206896551724,
      "grad_norm": 2.8896636962890625,
      "learning_rate": 0.0002649350649350649,
      "loss": 12.3001,
      "step": 31
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 3.873629570007324,
      "learning_rate": 0.0002636363636363636,
      "loss": 12.6123,
      "step": 32
    },
    {
      "epoch": 0.4267241379310345,
      "grad_norm": 5.52213716506958,
      "learning_rate": 0.00026233766233766233,
      "loss": 13.0068,
      "step": 33
    },
    {
      "epoch": 0.4396551724137931,
      "grad_norm": 3.8918497562408447,
      "learning_rate": 0.000261038961038961,
      "loss": 12.7296,
      "step": 34
    },
    {
      "epoch": 0.4525862068965517,
      "grad_norm": 4.151779651641846,
      "learning_rate": 0.00025974025974025974,
      "loss": 12.7894,
      "step": 35
    },
    {
      "epoch": 0.46551724137931033,
      "grad_norm": 4.28049898147583,
      "learning_rate": 0.00025844155844155845,
      "loss": 12.176,
      "step": 36
    },
    {
      "epoch": 0.47844827586206895,
      "grad_norm": 3.344611883163452,
      "learning_rate": 0.0002571428571428571,
      "loss": 9.3734,
      "step": 37
    },
    {
      "epoch": 0.49137931034482757,
      "grad_norm": 4.029280185699463,
      "learning_rate": 0.0002558441558441558,
      "loss": 11.7098,
      "step": 38
    },
    {
      "epoch": 0.5043103448275862,
      "grad_norm": 4.853503227233887,
      "learning_rate": 0.0002545454545454545,
      "loss": 12.6607,
      "step": 39
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 3.959879159927368,
      "learning_rate": 0.0002532467532467532,
      "loss": 11.6397,
      "step": 40
    },
    {
      "epoch": 0.5301724137931034,
      "grad_norm": 4.6632795333862305,
      "learning_rate": 0.0002519480519480519,
      "loss": 12.8616,
      "step": 41
    },
    {
      "epoch": 0.5431034482758621,
      "grad_norm": 4.517310619354248,
      "learning_rate": 0.0002506493506493506,
      "loss": 13.1835,
      "step": 42
    },
    {
      "epoch": 0.5560344827586207,
      "grad_norm": 3.2161476612091064,
      "learning_rate": 0.00024935064935064933,
      "loss": 12.4197,
      "step": 43
    },
    {
      "epoch": 0.5689655172413793,
      "grad_norm": 3.9185047149658203,
      "learning_rate": 0.00024805194805194804,
      "loss": 11.832,
      "step": 44
    },
    {
      "epoch": 0.5818965517241379,
      "grad_norm": 4.3378987312316895,
      "learning_rate": 0.00024675324675324674,
      "loss": 12.0122,
      "step": 45
    },
    {
      "epoch": 0.5948275862068966,
      "grad_norm": 4.143579006195068,
      "learning_rate": 0.00024545454545454545,
      "loss": 12.1129,
      "step": 46
    },
    {
      "epoch": 0.6077586206896551,
      "grad_norm": 3.166975736618042,
      "learning_rate": 0.00024415584415584415,
      "loss": 12.8142,
      "step": 47
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 3.494629383087158,
      "learning_rate": 0.00024285714285714283,
      "loss": 10.8532,
      "step": 48
    },
    {
      "epoch": 0.6336206896551724,
      "grad_norm": 3.337921380996704,
      "learning_rate": 0.00024155844155844154,
      "loss": 11.8737,
      "step": 49
    },
    {
      "epoch": 0.646551724137931,
      "grad_norm": 3.7817816734313965,
      "learning_rate": 0.00024025974025974024,
      "loss": 11.0386,
      "step": 50
    },
    {
      "epoch": 0.6594827586206896,
      "grad_norm": 3.4227616786956787,
      "learning_rate": 0.00023896103896103895,
      "loss": 12.0516,
      "step": 51
    },
    {
      "epoch": 0.6724137931034483,
      "grad_norm": 3.824897050857544,
      "learning_rate": 0.00023766233766233765,
      "loss": 10.0321,
      "step": 52
    },
    {
      "epoch": 0.6853448275862069,
      "grad_norm": 4.330126762390137,
      "learning_rate": 0.00023636363636363633,
      "loss": 12.1112,
      "step": 53
    },
    {
      "epoch": 0.6982758620689655,
      "grad_norm": 2.9986732006073,
      "learning_rate": 0.00023506493506493504,
      "loss": 11.4283,
      "step": 54
    },
    {
      "epoch": 0.7112068965517241,
      "grad_norm": 3.0932910442352295,
      "learning_rate": 0.00023376623376623374,
      "loss": 10.9379,
      "step": 55
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 3.3554084300994873,
      "learning_rate": 0.00023246753246753242,
      "loss": 10.0465,
      "step": 56
    },
    {
      "epoch": 0.7370689655172413,
      "grad_norm": 3.003232479095459,
      "learning_rate": 0.00023116883116883116,
      "loss": 10.3131,
      "step": 57
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.816528081893921,
      "learning_rate": 0.00022987012987012986,
      "loss": 8.3072,
      "step": 58
    },
    {
      "epoch": 0.7629310344827587,
      "grad_norm": 3.3908424377441406,
      "learning_rate": 0.00022857142857142854,
      "loss": 11.476,
      "step": 59
    },
    {
      "epoch": 0.7758620689655172,
      "grad_norm": 3.0751357078552246,
      "learning_rate": 0.00022727272727272725,
      "loss": 9.5416,
      "step": 60
    },
    {
      "epoch": 0.7887931034482759,
      "grad_norm": 4.440732955932617,
      "learning_rate": 0.00022597402597402595,
      "loss": 10.3947,
      "step": 61
    },
    {
      "epoch": 0.8017241379310345,
      "grad_norm": 3.1682794094085693,
      "learning_rate": 0.00022467532467532463,
      "loss": 10.8112,
      "step": 62
    },
    {
      "epoch": 0.8146551724137931,
      "grad_norm": 4.872435092926025,
      "learning_rate": 0.00022337662337662336,
      "loss": 9.4813,
      "step": 63
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 4.583402633666992,
      "learning_rate": 0.00022207792207792207,
      "loss": 10.7395,
      "step": 64
    },
    {
      "epoch": 0.8405172413793104,
      "grad_norm": 2.910429000854492,
      "learning_rate": 0.00022077922077922075,
      "loss": 11.1816,
      "step": 65
    },
    {
      "epoch": 0.853448275862069,
      "grad_norm": 3.464561939239502,
      "learning_rate": 0.00021948051948051945,
      "loss": 9.2225,
      "step": 66
    },
    {
      "epoch": 0.8663793103448276,
      "grad_norm": 3.3045012950897217,
      "learning_rate": 0.00021818181818181816,
      "loss": 10.4823,
      "step": 67
    },
    {
      "epoch": 0.8793103448275862,
      "grad_norm": 3.530181407928467,
      "learning_rate": 0.00021688311688311684,
      "loss": 10.5763,
      "step": 68
    },
    {
      "epoch": 0.8922413793103449,
      "grad_norm": 3.5994646549224854,
      "learning_rate": 0.00021558441558441557,
      "loss": 10.6001,
      "step": 69
    },
    {
      "epoch": 0.9051724137931034,
      "grad_norm": 2.8888847827911377,
      "learning_rate": 0.00021428571428571427,
      "loss": 11.4698,
      "step": 70
    },
    {
      "epoch": 0.9181034482758621,
      "grad_norm": 3.3341593742370605,
      "learning_rate": 0.00021298701298701298,
      "loss": 8.9128,
      "step": 71
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 2.9974467754364014,
      "learning_rate": 0.00021168831168831166,
      "loss": 10.4517,
      "step": 72
    },
    {
      "epoch": 0.9439655172413793,
      "grad_norm": 3.493880033493042,
      "learning_rate": 0.00021038961038961036,
      "loss": 11.2871,
      "step": 73
    },
    {
      "epoch": 0.9568965517241379,
      "grad_norm": 2.766749382019043,
      "learning_rate": 0.0002090909090909091,
      "loss": 9.5786,
      "step": 74
    },
    {
      "epoch": 0.9698275862068966,
      "grad_norm": 3.636368751525879,
      "learning_rate": 0.00020779220779220778,
      "loss": 10.0376,
      "step": 75
    },
    {
      "epoch": 0.9827586206896551,
      "grad_norm": 3.9716851711273193,
      "learning_rate": 0.00020649350649350648,
      "loss": 10.6453,
      "step": 76
    },
    {
      "epoch": 0.9956896551724138,
      "grad_norm": 3.3088743686676025,
      "learning_rate": 0.0002051948051948052,
      "loss": 10.8774,
      "step": 77
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7290042638778687,
      "learning_rate": 0.00020389610389610387,
      "loss": 3.1406,
      "step": 78
    },
    {
      "epoch": 1.0,
      "eval_loss": 3.3748056888580322,
      "eval_runtime": 121.4753,
      "eval_samples_per_second": 0.214,
      "eval_steps_per_second": 0.214,
      "step": 78
    }
  ],
  "logging_steps": 1,
  "max_steps": 231,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6106117494996992e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
