{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Domain Adaptation using QLoRA\n\nThis notebook demonstrates how to:\n1. Extract text from a technical PDF\n2. Prepare training data for causal language modelling (CLM)\n3. Fine-tune a language (llama 3.2 3b) base model using QLoRA\n4. Apply the QLoRA and the learned weights to the instruct model\n5. Answer some test questions","metadata":{}},{"cell_type":"code","source":"# Clone the git repo to access the utilities\n!git clone https://github.com/arminwitte/mistral-peft mistralpeft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:08:10.049944Z","iopub.execute_input":"2025-02-24T13:08:10.05034Z","iopub.status.idle":"2025-02-24T13:08:10.185746Z","shell.execute_reply.started":"2025-02-24T13:08:10.0503Z","shell.execute_reply":"2025-02-24T13:08:10.184652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make sure to be on the repo directory and pull\nimport os\nif not os.getcwd() == \"/kaggle/working/mistralpeft\":\n    os.chdir(\"/kaggle/working/mistralpeft\")\n!pwd\n!git fetch --all\n!git reset --hard origin/main","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:08:10.187414Z","iopub.execute_input":"2025-02-24T13:08:10.187786Z","iopub.status.idle":"2025-02-24T13:08:34.369214Z","shell.execute_reply.started":"2025-02-24T13:08:10.187747Z","shell.execute_reply":"2025-02-24T13:08:34.368401Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install the required packages from pypi\n!pip install -r requirements.txt --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:08:34.370828Z","iopub.execute_input":"2025-02-24T13:08:34.371087Z","iopub.status.idle":"2025-02-24T13:08:41.571288Z","shell.execute_reply.started":"2025-02-24T13:08:34.371063Z","shell.execute_reply":"2025-02-24T13:08:41.570072Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load packages\nfrom transformers import Trainer, TrainingArguments, AutoTokenizer, pipeline\nfrom pathlib import Path\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftConfig, PeftModel\nfrom datasets import Dataset\n\nfrom mistralpeft.utils import TextExtractor, CLMPreprocessor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:08:41.573379Z","iopub.execute_input":"2025-02-24T13:08:41.573787Z","iopub.status.idle":"2025-02-24T13:09:04.380072Z","shell.execute_reply.started":"2025-02-24T13:08:41.573749Z","shell.execute_reply":"2025-02-24T13:09:04.379222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Login to HuggingFace using Kaggle's secrets to be able to download models\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"huggingface\")\nlogin(secret_value_0) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:09:04.380896Z","iopub.execute_input":"2025-02-24T13:09:04.381502Z","iopub.status.idle":"2025-02-24T13:09:04.927251Z","shell.execute_reply.started":"2025-02-24T13:09:04.381477Z","shell.execute_reply":"2025-02-24T13:09:04.926358Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Extract Sentences from PDF\nSeveral PDFs from my former research group at university (Thermo-Fluiddynamics Group, Prof. Polifke) are chosen to form the corpus","metadata":{}},{"cell_type":"code","source":"# TextExtractor is a simple ETL class to acquire a text corpus\npdf_files = [\n    \"Dissertation.pdf\",\n]\n    \npdf_urls = [\n    \"https://mediatum.ub.tum.de/doc/1360567/1360567.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1601190/1601190.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1597610/1597610.pdf\"\n    \"https://mediatum.ub.tum.de/doc/1584750/1584750.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1484812/1484812.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1335646/1335646.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1326486/1326486.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1306410/1306410.pdf\",\n    \"https://mediatum.ub.tum.de/doc/1444929/1444929.pdf\",\n]\n\ndata_path = Path(\"data/processed_documents.json\")\nif not data_path.is_file():\n    with TextExtractor(\"data/processed_documents.json\") as extractor:\n        # Process local files\n        extractor.process_documents(pdf_files)\n            \n        # Process URLs\n        extractor.process_documents(pdf_urls, url_list=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:09:04.928289Z","iopub.execute_input":"2025-02-24T13:09:04.9286Z","iopub.status.idle":"2025-02-24T13:09:04.932887Z","shell.execute_reply.started":"2025-02-24T13:09:04.928577Z","shell.execute_reply":"2025-02-24T13:09:04.931998Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Prepare MCLM Training Data","metadata":{}},{"cell_type":"code","source":"# Specify the model and load the tokenizer\n# Llama 3.2 3B with approx. 3 billion parameters\nmodel_name = \"mistralai/Mistral-7B-v0.3\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:09:04.933619Z","iopub.execute_input":"2025-02-24T13:09:04.933826Z","iopub.status.idle":"2025-02-24T13:09:08.656341Z","shell.execute_reply.started":"2025-02-24T13:09:04.933808Z","shell.execute_reply":"2025-02-24T13:09:08.655621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocess the corpus for Causal Language Modeling (CLM)\njson_file_paths = [\"data/processed_documents.json\"]\npreprocessor = CLMPreprocessor(json_file_paths, tokenizer)\ndataset = preprocessor.preprocess()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:09:08.658605Z","iopub.execute_input":"2025-02-24T13:09:08.658835Z","iopub.status.idle":"2025-02-24T13:09:12.531418Z","shell.execute_reply.started":"2025-02-24T13:09:08.658816Z","shell.execute_reply":"2025-02-24T13:09:12.530682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split into training and test set\ntrain_test_set = dataset.train_test_split(test_size=0.1)\nprint(f\"Created {len(train_test_set['train'])} training examples and {len(train_test_set['test'])} test examples\")\n\n# Preview a training example\nexample = train_test_set[\"train\"][0]\nprint(\"\\nExample input:\")\nprint(preprocessor.tokenizer.decode(example['input_ids'][:256]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:09:12.533725Z","iopub.execute_input":"2025-02-24T13:09:12.533967Z","iopub.status.idle":"2025-02-24T13:09:12.563558Z","shell.execute_reply.started":"2025-02-24T13:09:12.533948Z","shell.execute_reply":"2025-02-24T13:09:12.562681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Load and Prepare Model","metadata":{}},{"cell_type":"code","source":"# Load the base model\n# Q4_K_M quantization of the base model is achieved through BitsAndBytes. It requires CUDA!\nquantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,  # Use load_in_4bit=True for 4-bit quantization\n        bnb_4bit_quant_type=\"nf4\", # use normalized float 4\n        bnb_4bit_compute_dtype=torch.float16,\n        bnb_4bit_use_double_quant=False, # do not quantize scaling factors for Q4_K_M\n    )\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    quantization_config=quantization_config,\n    )\nif base_model.config.pad_token_id is None:\n    base_model.config.pad_token_id = base_model.config.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:09:12.564302Z","iopub.execute_input":"2025-02-24T13:09:12.564512Z","iopub.status.idle":"2025-02-24T13:11:55.153307Z","shell.execute_reply.started":"2025-02-24T13:09:12.564495Z","shell.execute_reply":"2025-02-24T13:11:55.152246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configure the (Q)LoRA adaptor to use a rank of r=4\nmodel = prepare_model_for_kbit_training(base_model)\nconfig = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\",],# \"o_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\npeft_model = get_peft_model(model, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:11:55.154298Z","iopub.execute_input":"2025-02-24T13:11:55.154622Z","iopub.status.idle":"2025-02-24T13:11:55.643445Z","shell.execute_reply.started":"2025-02-24T13:11:55.154599Z","shell.execute_reply":"2025-02-24T13:11:55.642747Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Train the Model\n\nThe LoRA adapter has about 6M parameters to train (compared to 3B parameters of the full LLM)","metadata":{}},{"cell_type":"code","source":"# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=4,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=4, # Creates a virtual batch size of 3\n    learning_rate=1e-4,\n    fp16=True, # numerical precision of adapter is float16\n    logging_steps=1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    optim=\"paged_adamw_8bit\", # Memory efficient optimizer\n    log_level=\"info\",\n    report_to=\"none\",\n)\n\n# Initialize trainer\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=train_test_set['train'],\n    eval_dataset=train_test_set['test']\n)\n\n# Start training\ntrainer.train(resume_from_checkpoint=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:15:27.507738Z","iopub.execute_input":"2025-02-24T13:15:27.508079Z","iopub.status.idle":"2025-02-24T13:15:28.666733Z","shell.execute_reply.started":"2025-02-24T13:15:27.508055Z","shell.execute_reply":"2025-02-24T13:15:28.666011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the LoRA adapter weights:\nlora_save_path = \"lora_weights\" \npeft_model.save_pretrained(lora_save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:15:48.631142Z","iopub.execute_input":"2025-02-24T13:15:48.631512Z","iopub.status.idle":"2025-02-24T13:15:49.366185Z","shell.execute_reply.started":"2025-02-24T13:15:48.631482Z","shell.execute_reply":"2025-02-24T13:15:49.365532Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Test the Model","metadata":{}},{"cell_type":"markdown","source":"peft_model = PeftModel.from_pretrained(base_model, \"results/checkpoint-231\")","metadata":{}},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(base_model, lora_save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:15:57.406576Z","iopub.execute_input":"2025-02-24T13:15:57.406876Z","iopub.status.idle":"2025-02-24T13:15:57.926615Z","shell.execute_reply.started":"2025-02-24T13:15:57.406855Z","shell.execute_reply":"2025-02-24T13:15:57.925914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_continuation(model, tokenizer):# Example queries\n    queries = [\n        \"SI is used when processes are either too complex to gain insight using first principles, i.e. physical laws, or the calculation is too costly in terms of time or resources. Its goal is to\",\n        \"In pulsating or oscillating flow, heat transfer can damp, but also drive instabilities.\",\n        \"The unit impulse response is a time domain model. It shows\",\n    ]\n    \n    # Generate responses\n    for query in queries:\n            \n        inputs = tokenizer(query, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n        \n        outputs = model.generate(**inputs, max_new_tokens=150, num_return_sequences=1)\n        \n        text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        print(f\"\\nQuery: {query}\")\n        print(f\"\\nResponse: {text}\")\n        print(\"-\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:16:00.199256Z","iopub.execute_input":"2025-02-24T13:16:00.199771Z","iopub.status.idle":"2025-02-24T13:16:00.205964Z","shell.execute_reply.started":"2025-02-24T13:16:00.199716Z","shell.execute_reply":"2025-02-24T13:16:00.204944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### 6.1 Answers to the test questions by the instruct model w/o LoRA","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:14:42.939155Z","iopub.status.idle":"2025-02-24T13:14:42.939551Z","shell.execute_reply":"2025-02-24T13:14:42.939374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6.2 Answers to the test questions by the adapted model","metadata":{}},{"cell_type":"code","source":"test_continuation(base_model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:16:04.339067Z","iopub.execute_input":"2025-02-24T13:16:04.339427Z","iopub.status.idle":"2025-02-24T13:16:37.137775Z","shell.execute_reply.started":"2025-02-24T13:16:04.3394Z","shell.execute_reply":"2025-02-24T13:16:37.137015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_continuation(peft_model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T13:16:49.758396Z","iopub.execute_input":"2025-02-24T13:16:49.758733Z","iopub.status.idle":"2025-02-24T13:17:22.501515Z","shell.execute_reply.started":"2025-02-24T13:16:49.7587Z","shell.execute_reply":"2025-02-24T13:17:22.500585Z"}},"outputs":[],"execution_count":null}]}